---
title: "éƒ¨ç½²prometheus"
layout: post
date: 2020-03-03 15:38
image: /assets/images/markdown.jpg
headerImage: false
tag:
- Tech
category: blog
author: dong

---
# éƒ¨ç½²prometheus

æœ¬æ–‡æ˜¯ä¸€æ­¥æ­¥ä»éƒ¨ç½²operatorï¼Œ prometheusï¼Œ serviceaccountï¼Œalertmanager æ¥ç†Ÿæ‚‰éƒ¨ç½²æµç¨‹ã€‚

å¦‚æœå·²ç»å¾ˆç†Ÿæ‚‰äº†ï¼Œå¯ä»¥é€šè¿‡[kube-prometheus](https://github.com/coreos/kube-prometheus) å®Œæˆå¿«é€Ÿä¸€é”®éƒ¨ç½²

## é€šè¿‡éƒ¨ç½²prometheus operator

### minikubeå‡†å¤‡

æœ¬æœºæ“ä½œç›´æ¥ç”¨çš„minikube

**é‡æ–°å®‰è£…æœ€æ–°ç‰ˆ**

[install-minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/)

```
minikube stop

minikube delete ( ç¡®ä¿å…ˆå…ˆåˆ æ‰)

brew install minikube

sudo mv minikube /usr/local/bin

é€šè¿‡minikube versionæŸ¥çœ‹æ˜¯å¦æˆåŠŸ

(å¯ä»¥é€šè¿‡which minikube  æŸ¥æ‰¾å®‰è£…è·¯å¾„)

```

```
brew upgrade kubectl

å®‰è£…å®Œæ¯•ï¼Œé€šè¿‡ kubectl version æŸ¥çœ‹ä¸‹æ˜¯å¦å®‰è£…æˆåŠŸ, çœ‹gitversion

Client Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.1", GitCommit:"7879fc12a63337efff607952a323df90cdc7a335", GitTreeState:"clean", BuildDate:"2020-04-10T21:53:40Z", GoVersion:"go1.14.2", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"17", GitVersion:"v1.17.3", GitCommit:"06ad960bfd03b39c8310aaf92d1e7c12ce618213", GitTreeState:"clean", BuildDate:"2020-02-11T18:07:13Z", GoVersion:"go1.13.6", Compiler:"gc", Platform:"linux/amd64"}

```


### å¯åŠ¨minikube
é€šå¸¸å›½å†…å¢™çš„é—®é¢˜è¿˜æ˜¯é…ä¸€ä¸‹ä»£ç†

```
export  HTTP_PROXY=http://proxy:8080
export HTTPS_PROXY=http://proxy:8080
export no_proxy=localhost,127.0.0.1,10.96.0.0/12,192.168.99.0/24,192.168.39.0/24,192.168.64.4
export no_proxy=$no_proxy,$(minikube ip)

curl https://k8s.gcr.io/robots.txt  éªŒè¯
```

```
âœ  ~ minikube start
ğŸ˜„  Darwin 10.13.6 ä¸Šçš„ minikube v1.9.2
âœ¨  æ ¹æ®ç°æœ‰çš„é…ç½®æ–‡ä»¶ä½¿ç”¨ hyperkit é©±åŠ¨ç¨‹åº
ğŸ‘  Kubernetes 1.18.0 ç°åœ¨å¯ç”¨äº†ã€‚å¦‚æœæ‚¨æƒ³å‡çº§ï¼Œè¯·æŒ‡å®š --kubernetes-version=1.18.0
ğŸ‘  Starting control plane node m01 in cluster minikube
ğŸ’¾  Downloading Kubernetes v1.17.3 preload ...
ğŸƒ  Updating the running hyperkit "minikube" VM ...
ğŸŒ  æ‰¾åˆ°çš„ç½‘ç»œé€‰é¡¹ï¼š
    â–ª HTTP_PROXY=http://proxy:8080
â—  æ‚¨ä¼¼ä¹æ­£åœ¨ä½¿ç”¨ä»£ç†ï¼Œä½†æ‚¨çš„ NO_PROXY ç¯å¢ƒä¸åŒ…å« minikube IP (192.168.64.4)ã€‚å¦‚éœ€äº†è§£è¯¦æƒ…ï¼Œè¯·å‚é˜… https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
    â–ª HTTPS_PROXY=http://proxy:8080
    â–ª NO_PROXY=localhost,127.0.0.1,10.96.0.0/12,192.168.99.0/24,192.168.39.0/24
    â–ª no_proxy=,192.168.64.4
ğŸ³  æ­£åœ¨ Docker 19.03.8 ä¸­å‡†å¤‡ Kubernetes v1.17.3â€¦
    â–ª env HTTP_PROXY=http://proxy:8080
    â–ª env HTTPS_PROXY=http://proxy:8080
    â–ª env NO_PROXY=localhost,127.0.0.1,10.96.0.0/12,192.168.99.0/24,192.168.39.0/24
    â–ª env NO_PROXY=,192.168.64.4
ğŸŒŸ  Enabling addons: default-storageclass, storage-provisioner
â—  Enabling 'default-storageclass' returned an error: running callbacks: [Error making standard the default storage class: Error listing StorageClasses: Get "https://192.168.64.4:8443/apis/storage.k8s.io/v1/storageclasses": Service Unavailable]
ğŸ„  å®Œæˆï¼kubectl å·²ç»é…ç½®è‡³ "minikube"

```

### éƒ¨ç½²Prometheus operator


åœ¨Kubernetesä¸­å®‰è£…Prometheus Operatoréå¸¸ç®€å•ï¼Œç”¨æˆ·å¯ä»¥ä»ä»¥ä¸‹åœ°å€ä¸­è¿‡å»Prometheus Operatorçš„æºç ï¼š
```
git clone https://github.com/coreos/prometheus-operator.git
```
è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºPromethues Operatoråˆ›å»ºä¸€ä¸ªå•ç‹¬çš„å‘½åç©ºé—´monitoringï¼š
```
kubectl create namespace monitoring
```
ç”±äºéœ€è¦å¯¹Prometheus Operatorè¿›è¡ŒRBACæˆæƒï¼Œè€Œé»˜è®¤çš„bundle.yamlä¸­ä½¿ç”¨äº†defaultå‘½åç©ºé—´ï¼Œå› æ­¤ï¼Œåœ¨å®‰è£…Prometheus Operatorä¹‹å‰éœ€è¦å…ˆæ›¿æ¢ä¸€ä¸‹bundle.yamlæ–‡ä»¶ä¸­æ‰€æœ‰namespaceå®šä¹‰ï¼Œç”±defaultä¿®æ”¹ä¸ºmonitoringã€‚ é€šè¿‡è¿è¡Œä¸€ä¸‹å‘½ä»¤å®‰è£…Prometheus Operatorçš„Deploymentå®ä¾‹ï¼š
```
$ kubectl -n monitoring apply -f bundle.yaml
clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created
clusterrole.rbac.authorization.k8s.io/prometheus-operator created
deployment.apps/prometheus-operator created
serviceaccount/prometheus-operator created
service/prometheus-operator created

```

### åˆ›å»ºPrometheuså®ä¾‹, alertmanager, example-app

å…·ä½“æ­¥éª¤å¯ä»¥å‚è€ƒ[prometheus-book](https://github.com/yunlzheng/prometheus-book/blob/master/operator/use-operator-manage-monitor.md)
[Demoä»£ç ](../codes/prometheus-operator-demo)

æœ€åå…¨éƒ¨éƒ¨ç½²å®Œæˆåï¼Œè¿™äº›åœ°å€è®¿é—®prometheus

http://127.0.0.1:8080/

http://127.0.0.1:9090/

http://127.0.0.1:9093/

podåº”è¯¥æœ‰è¿™äº› kubectl get all

```
NAME                                      READY   STATUS    RESTARTS   AGE
pod/alertmanager-inst-0                   2/2     Running   0          16h
pod/alertmanager-inst-1                   2/2     Running   0          16h
pod/alertmanager-inst-2                   2/2     Running   0          15h
pod/example-app-5cc7db675f-5vmxc          1/1     Running   0          105m
pod/example-app-5cc7db675f-bv7s5          1/1     Running   0          21h
pod/example-app-5cc7db675f-tgnx5          1/1     Running   0          105m
pod/prometheus-inst-0                     3/3     Running   1          17h
pod/prometheus-operator-7676db7c9-ksrvw   1/1     Running   0          22h

NAME                            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
service/alertmanager-operated   ClusterIP   None            <none>        9093/TCP,9094/TCP,9094/UDP   16h
service/example-app             ClusterIP   10.98.190.166   <none>        8080/TCP                     22h
service/prometheus-operated     ClusterIP   None            <none>        9090/TCP                     22h
service/prometheus-operator     ClusterIP   None            <none>        8080/TCP                     22h

NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/example-app           3/3     3            3           21h
deployment.apps/prometheus-operator   1/1     1            1           22h

NAME                                            DESIRED   CURRENT   READY   AGE
replicaset.apps/example-app-5cc7db675f          3         3         3       21h
replicaset.apps/prometheus-operator-7676db7c9   1         1         1       22h

NAME                                 READY   AGE
statefulset.apps/alertmanager-inst   3/3     16h
statefulset.apps/prometheus-inst     1/1     22h
```

### FQA

é€šè¿‡--docker-env HTTP_PROXY=http://proxy:8080 å®‰è£…ï¼Œ è¿˜æ˜¯é‡åˆ°äº†æŠ¥é”™
```
minikube start --docker-env HTTP_PROXY=http://proxy:8080  --docker-env HTTPS_PROXY=http://proxy:8080
```

åœ¨minikube start åé¢åŠ ä¸ªå‚æ•° -v 8 --alsologtostderr  çœ‹è¯¦ç»†æ—¥å¿—
```
E0415 19:19:20.533152   33433 cache.go:63] save image to file "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> "/Users/dongshu/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1" failed: nil image for gcr.io/k8s-minikube/storage-provisioner:v1.8.1: Get "https://gcr.io/v2/": dial tcp 64.233.189.82:443: i/o timeout
W0415 19:19:20.592870   33433 cache.go:118] unable to retrieve image: Get "https://k8s.gcr.io/v2/": dial tcp 74.125.203.82:443: i/o timeout
I0415 19:19:20.592942   33433 cache.go:81] cache image "k8s.gcr.io/kube-proxy:v1.17.3" -> "/Users/dongshu/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.3" took 5m8.804223272s
E0415 19:19:20.592963   33433 cache.go:63] save image to file "k8s.gcr.io/kube-proxy:v1.17.3" -> "/Users/dongshu/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.3" failed: nil image for k8s.gcr.io/kube-proxy:v1.17.3: Get "https://k8s.gcr.io/v2/": dial tcp 74.125.203.82:443: i/o timeout
W0415 19:19:20.596016   33433 cache.go:118] unable to retrieve image: Get "https://k8s.gcr.io/v2/": dial tcp 74.125.203.82:443: i/o timeout
I0415 19:19:20.596068   33433 cache.go:81] cache image "k8s.gcr.io/pause:3.1" -> "/Users/dongshu/.minikube/cache/images/k8s.gcr.io/pause_3.1" took 5m8.803245971s
E0415 19:19:20.596083   33433 cache.go:63] save image to file "k8s.gcr.io/pause:3.1" -> "/Users/dongshu/.minikube/cache/images/k8s.gcr.io/pause_3.1" failed: nil image for k8s.gcr.io/pause:3.1: Get "https://k8s.gcr.io/v2/": dial tcp 74.125.203.82:443: i/o timeout
W0415 19:19:20.596612   33433 exit.go:101] Failed to cache images: Caching images for kubeadm: caching images: caching image "/Users/dongshu/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.3": nil image for k8s.gcr.io/kube-controller-manager:v1.17.3: Get "https://k8s.gcr.io/v2/": dial tcp 74.125.203.82:443: i/o timeout

ğŸ’£  ç¼“å­˜é•œåƒæ—¶å¤±è´¥: Caching images for kubeadm: caching images: caching image "/Users/dongshu/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.3": nil image for k8s.gcr.io/kube-controller-manager:v1.17.3: Get "https://k8s.gcr.io/v2/": dial tcp 74.125.203.82:443: i/o timeout
```
